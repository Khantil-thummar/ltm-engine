# =============================================================================
# LTM Engine Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# OpenAI API Configuration
# -----------------------------------------------------------------------------

# Your OpenAI API key (required)
# Get it from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here

# -----------------------------------------------------------------------------
# LLM Settings
# -----------------------------------------------------------------------------

# Model used for reasoning tasks (conflict resolution, summarization, subject extraction)
# Options: gpt-4o-mini, gpt-4o, gpt-4-turbo, gpt-3.5-turbo
LLM_MODEL=gpt-4o-mini

# Controls randomness in LLM responses (0.0 = deterministic, 2.0 = very random)
# Lower values recommended for consistent memory operations
LLM_TEMPERATURE=0.1

# Maximum tokens the LLM can generate in a single response
# Increase if you need longer summaries or analyses
LLM_MAX_TOKENS=1024

# -----------------------------------------------------------------------------
# Embedding Settings
# -----------------------------------------------------------------------------

# Model used for generating vector embeddings for semantic search
# Options: text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
EMBEDDING_MODEL=text-embedding-3-small

# Dimensions of the embedding vectors (must match the model's output)
# text-embedding-3-small: 1536, text-embedding-3-large: 3072
EMBEDDING_DIMENSIONS=1536

# -----------------------------------------------------------------------------
# PostgreSQL Configuration
# -----------------------------------------------------------------------------

# PostgreSQL host (use 'localhost' for local, container name for Docker network)
POSTGRES_HOST=localhost

# PostgreSQL port
POSTGRES_PORT=5432

# Database credentials
POSTGRES_USER=ltm_user
POSTGRES_PASSWORD=ltm_password

# Database name for storing structured memory data
POSTGRES_DB=ltm_db

# -----------------------------------------------------------------------------
# Qdrant Configuration (Vector Database)
# -----------------------------------------------------------------------------

# Qdrant host (use 'localhost' for local, container name for Docker network)
QDRANT_HOST=localhost

# Qdrant REST API port
QDRANT_PORT=6333

# Collection name for storing memory embeddings
QDRANT_COLLECTION_NAME=ltm_memories

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------

# Host to bind the API server (0.0.0.0 = all interfaces)
SERVER_HOST=0.0.0.0

# Port for the API server
SERVER_PORT=8000

# Enable debug mode (true = verbose logging, auto-reload)
DEBUG=false

# -----------------------------------------------------------------------------
# Memory Configuration
# -----------------------------------------------------------------------------

# Default number of results to return in retrieval queries
DEFAULT_TOP_K=10

# Half-life for memory decay in days
# Memories lose half their importance score after this many days of no access
DECAY_HALF_LIFE_DAYS=30

# Minimum episodic memories required before consolidation can run
# Lower = consolidate more frequently, Higher = wait for more context
CONSOLIDATION_MIN_MEMORIES=5

# Maximum episodic memories to process in a single consolidation batch
# Higher = more comprehensive summaries, but slower and more costly
CONSOLIDATION_MAX_MEMORIES=50

# Minimum confidence threshold for keeping memories (0.0 to 1.0)
# Memories below this threshold may be forgotten during cleanup
MIN_CONFIDENCE_THRESHOLD=0.1

# -----------------------------------------------------------------------------
# Multi-Agent Configuration
# -----------------------------------------------------------------------------

# Default agent ID used when no agent is specified in API calls
DEFAULT_AGENT_ID=default

# Enable agent isolation (true = agents can only access their own memories)
ENABLE_AGENT_ISOLATION=true
